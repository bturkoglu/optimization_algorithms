1. GiriÅŸ
Dwarf Mongoose Optimization Algorithm (DMOA), cÃ¼ce mangustalarÄ±n sosyal davranÄ±ÅŸlarÄ±ndan esinlenerek geliÅŸtirilmiÅŸ bir meta-sezgisel optimizasyon algoritmasÄ±dÄ±r. Bu algoritma, mangustalarÄ±n yeni bÃ¶lgeleri keÅŸfetme ve mevcut bÃ¶lgelerdeki kaynaklarÄ± optimize etme stratejilerini taklit eder. DMOA, yÃ¼ksek boyutlu ve karmaÅŸÄ±k optimizasyon problemlerinde etkili bir performans gÃ¶stermektedir.

2. Temel Ã–zellikler
KeÅŸif ve SÃ¶mÃ¼rÃ¼ Dengesi: DMOA, yeni bÃ¶lgeleri keÅŸfetme ve mevcut iyi Ã§Ã¶zÃ¼mleri iyileÅŸtirme arasÄ±nda dengeli bir yapÄ± sunar.
Adaptif Mekanizmalar: Yerel minimumlardan kaÃ§Ä±nmak iÃ§in rastgele ve uyarlanabilir davranÄ±ÅŸlar kullanÄ±r.
Biyolojik Ä°lham: Algoritma, alfa grubu, keÅŸifÃ§i (scout) ve bakÄ±cÄ± (babysitter) rollerini simÃ¼le ederek optimizasyon sÃ¼recini yÃ¶nlendirir.
3. DMOAâ€™nÄ±n Ana BileÅŸenleri
PopÃ¼lasyon Boyutu (nPop): Algoritmadaki bireylerin sayÄ±sÄ±.
Ä°terasyon SayÄ±sÄ± (MaxIt): AlgoritmanÄ±n gerÃ§ekleÅŸtireceÄŸi toplam adÄ±m sayÄ±sÄ±.
DeÄŸiÅŸken AralÄ±ÄŸÄ± (VarMin, VarMax): Parametrelerin alt ve Ã¼st sÄ±nÄ±rlarÄ±.
Boyut SayÄ±sÄ± (nVar): Optimizasyon problemindeki deÄŸiÅŸken sayÄ±sÄ±.
AmaÃ§ Fonksiyonu (F_obj): Minimum deÄŸeri bulunmasÄ± gereken hedef fonksiyon.
4. AlgoritmanÄ±n AkÄ±ÅŸÄ±
PopÃ¼lasyonun BaÅŸlatÄ±lmasÄ±:
TÃ¼m bireylerin pozisyonlarÄ±, VarMin ve VarMax arasÄ±nda rastgele seÃ§ilir.

Alpha Grubu (Lider Grup):

Her iterasyonda lider grup bireyleri gÃ¼ncellenir.
Yeni pozisyonlar, komÅŸu bireyler arasÄ±ndaki farklara dayalÄ± olarak hesaplanÄ±r.
KeÅŸifÃ§i (Scout) Grubu:

Belli bir iterasyon sonrasÄ± baÅŸarÄ±sÄ±z bireyler rastgele pozisyonlara taÅŸÄ±nÄ±r.
Yeni pozisyonlar iÃ§in uyarlanabilir aÄŸÄ±rlÄ±klar kullanÄ±lÄ±r.
BakÄ±cÄ±lar (Babysitters):

Belli koÅŸullarda, bazÄ± bireyler popÃ¼lasyonun Ã§eÅŸitli bÃ¶lgelerine daÄŸÄ±tÄ±lÄ±r.
Konum GÃ¼ncelleme:
Konum gÃ¼ncelleme ÅŸu denkleme gÃ¶re yapÄ±lÄ±r:

YeniÂ Pozisyon
=
EskiÂ Pozisyon
+
ğœ™
â‹…
(
EskiÂ Pozisyon
âˆ’
Kom
s
Â¸
uÂ Pozisyon
)
YeniÂ Pozisyon=EskiÂ Pozisyon+Ï•â‹…(EskiÂ Pozisyonâˆ’Kom 
s
Â¸
â€‹
 uÂ Pozisyon)
Burada Ï† rastgele bir aÄŸÄ±rlÄ±k katsayÄ±sÄ±dÄ±r.

5. KeÅŸif ve SÃ¶mÃ¼rÃ¼ MekanizmalarÄ±
KeÅŸif MekanizmasÄ±:
Yeni pozisyonlar hesaplanÄ±rken bireylerin rastgele yÃ¶nlere hareket etmesi saÄŸlanÄ±r.

SÃ¶mÃ¼rÃ¼ MekanizmasÄ±:
Ä°yi sonuÃ§lar elde eden bireylerin etrafÄ±ndaki Ã§Ã¶zÃ¼mler iyileÅŸtirilir ve en iyi pozisyonlarÄ±n Ã§evresi daha detaylÄ± incelenir.

6. Algoritma Parametreleri
nBabysitter: BakÄ±cÄ± sayÄ±sÄ±, sÃ¶mÃ¼rÃ¼ aÅŸamalarÄ±nda kullanÄ±lÄ±r.
peep: Alfa bireyin vokalizasyon katsayÄ±sÄ±.
CF: Adaptasyon katsayÄ±sÄ±, iterasyon ilerledikÃ§e gÃ¼ncellenir.
7. Ã–rnek KullanÄ±m
python
Kodu kopyala
def sphere(x):
    return np.sum(x ** 2)

nPop = 50  # PopÃ¼lasyon bÃ¼yÃ¼klÃ¼ÄŸÃ¼
MaxIt = 100  # Maksimum iterasyon sayÄ±sÄ±
VarMin = -10  # Alt sÄ±nÄ±r
VarMax = 10  # Ãœst sÄ±nÄ±r
nVar = 5  # DeÄŸiÅŸken sayÄ±sÄ±

BEF, BEP, BestCost = DMOA(nPop, MaxIt, VarMin, VarMax, nVar, sphere)
print(f"En iyi fitness deÄŸeri: {BEF}")
print(f"En iyi pozisyon: {BEP}")
8. Ã‡Ä±ktÄ± ve Yorumlama
Her iterasyon iÃ§in en iyi fitness deÄŸeri yazdÄ±rÄ±lÄ±r.
Algoritma tamamlandÄ±ÄŸÄ±nda, en iyi pozisyon ve minimum deÄŸer ekrana basÄ±lÄ±r.
9. SonuÃ§ ve DeÄŸerlendirme
DMOA, keÅŸif ve sÃ¶mÃ¼rÃ¼ mekanizmalarÄ±nÄ± baÅŸarÄ±lÄ± bir ÅŸekilde birleÅŸtiren gÃ¼Ã§lÃ¼ bir optimizasyon algoritmasÄ±dÄ±r. PerformansÄ±, rastgele baÅŸlangÄ±Ã§ pozisyonlarÄ±na raÄŸmen etkileyici sonuÃ§lar sunar. Ancak, parametrelerin uygun seÃ§ilmesi, algoritmanÄ±n etkinliÄŸini artÄ±rabilir.